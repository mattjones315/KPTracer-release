{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sometimes Jupyter notebook doesn't retain your PATH environment variable -- this will mess up a number of things.\n",
    "## We recommend specifying the environment variable manually here\n",
    "\n",
    "from cassiopeia.TreeSolver import utilities\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pickle as pic\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The minimum input for reconstructing trees with Cassiopeia is a **character matrix** , consisting of indel measurements for **M** *characters* across **N** cells. Here, the term \"character\" is an abstract term referring to variables containing information about where cells lie in some phylogeny. In our technology, these are individual target sites -- i.e. those sites targeted by Cas9 and subsequently accumulate indels. More generally, these can be nulceotide positions in DNA or even phenotypic observations of an animal. \n",
    "\n",
    "We use this abstract data structure because it is general enough for any technology, and does not rely on any assumption other than one can *phase* the observations (i.e. you have the ability to index mutations by where they occurred). \n",
    "\n",
    "Here, we begin by describing how one takes an allele table from our PreProcessing Pipeline and converting into a character matrix. To do so, we not only specify an allele table but also a target lineage group (i.e. clone) to reconstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "alleletable_fp = \"lg_output/test.alleleTable.txt\" # relative file path to the allele table\n",
    "alleletable = pd.read_csv(alleletable_fp, sep='\\t')\n",
    "\n",
    "# here we're assuming there exists a 'lineage group' that's annotated in the allele table as LG4. \n",
    "# You can imagine subsetting your allele table differentely \n",
    "target_lg = 4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate Allele Proportions (i.e. State Priors)\n",
    "\n",
    "As a brief detour, we can estimate the indel priors from the allele tables by measuring the proportion of intBCs that report a given indel across independent clones. The idea behind this is that we'd like to subset the data into groups of independent sets (i.e. those that are not related to one another at all) as this will eliminate the possiblity of \"double counting\" indels because they were inherited. Inevitably, we will underestimate the propensity of a given indel to occur if it happened many times in the same location (as we choose to assume this only occurs by inheritance); however, the more independent groups we have, the greater our ability to estimate priors.\n",
    "\n",
    "The function ``get_indel_props`` will do this and takes the following arguments:\n",
    "\n",
    "- **at**: Allele Table Dataframe\n",
    "- **group_var**: A list of variables (columns in the allele table) by which to subset the data into independent groups (Default = ['intBC']). If you have redundant intBCs, you can also partition your data on the basis of intBCs and clone annotations (e.g. group_var = ['intBC', 'clone'])\n",
    "\n",
    "This will return a dataframe with three columns -- the indel identity, the proportion of groups it appeared in, and the frequency of this indel (an estimate of the prior probability)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Counting unique alleles: 100%|██████████| 124/124 [00:00<00:00, 9964.44it/s]\n"
     ]
    }
   ],
   "source": [
    "allele_props = utilities.get_indel_props(alleletable, group_var=['intBC', 'lineageGrp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create character matrix from a lineage group\n",
    "\n",
    "We now aggregate our observations from the allele table into a character matrix -- a matrix whose dimensions are `n x m`, where we have `n` cells and `m` characters (in our case, this is the number of total target sites, 3 times the number of integrations). We can use the ``alleletable_to_character_matrix`` function here, which takes the following parameters:\n",
    "\n",
    "- **at**: alleletable (subsetted for a particular lineage group) \n",
    "- **out_fp**: the output file path for the resulting character matrix (Default = None). This value is only necessary when ``write = True``.\n",
    "- **mutation_map**: the indel priors, calculated as above with ``get_indel_props``. If nothing is provided, no prior probabilities will be used for later tree reconstructions.\n",
    "- **no_context**: Use indels without context (default = False). If True, this means that the character matrix will only look at indel identity, not the context in which it appears.\n",
    "- **write**: Write to file (default = True).\n",
    "- **to_drop**: A set of intBCs that you'd like to ignore while creating a character matrix. \n",
    "- **allele_rep_thresh**: A maximum threshold of allele-dominance in a given character (default = 1.0). If one allele (i.e. indel) appears at higher than this proportion in a given character, the character is deemed uninformative and thrown out.  \n",
    "\n",
    "This function will return (or write) three files: \n",
    "- the character matrix\n",
    "- the indel proprotions dictionary, specifying the mutation probabilities for each character to a particular state\n",
    "- dictionary translating a state-character pair to an observed allele. \n",
    "\n",
    "If write is True, the last two files are saved as pickle files, and only written if a mutation_map is provided. Else, the dictionaries are returned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing characters: 100%|██████████| 45/45 [00:00<00:00, 1300.82it/s]\n"
     ]
    }
   ],
   "source": [
    "lg = alleletable[alleletable[\"lineageGrp\"] == target_lg]\n",
    "\n",
    "utilities.alleletable_to_character_matrix(lg, \"test_lg4_character_matrix.txt\", mutation_map=allele_props, write=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruct a lineage\n",
    "\n",
    "You can now reconstruct lineages using the `reconstruct-lineage` command, which takes in many different options depending on which of many lineage solvers you'd like to use. We provide Neighbor-Joining, Camin-Sokal (implemented with PHYLIP), greedy, Steiner-Tree/ILP, and Hybrid algorithms. Use the `-h` flag to see all possible parameters, or take a look at this walkthrough for tree reconstruction: [link to tree documentation].\n",
    "\n",
    "The output of this procedure will be a Cassiopeia_Tree object, which is essentially a wrapper for a networkx object representing the Tree, and a newick string that can be read in using a variety of different software. This object also contains several other utilities functions which can be found on our documentation website: https://cassiopeia-lineage.readthedocs.io/en/latest/Cassiopeia.TreeSolver.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-Processing a Tree\n",
    "\n",
    "Here we'll work with a tree named `test_lg4_tree.pkl`, and we assume it was reconstructed using the `reconstruct-lineage` command line tool and associated functions. If this is the case, Cassiopeia has returned what we call a *state-tree*: because multiple cells can report the same set of alleles, or states, Cassiopeia reconstructs over the unique states rather than all cells. It thus returns a tree that proposes a phylogenetic relationship over these states. Taken together, we'll need to append cells back to the leaves of the tree using the `post-process` functionality. This does three things:\n",
    "\n",
    "1. Map terminal character states to the cell identifiers\n",
    "2. Add \"Redundant\" leaves to the terminal leaves. This is necessary because if not ever cell represents a unique state, then the final tree would only be over a subset of the cells originally in the character matrix. This is known as the Post-Processing Tree Step.\n",
    "3. If there exist any \"leaves\" that do not correspond to character states observed in the character matrix, these are pruned back. \n",
    "\n",
    "While we provide the python code to do this, you can also take advantage of the `post-process-tree`. Use the `-h` flag to see options and usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mapping Terminal states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.read_gpickle(\"test_lg4_tree.pkl\") # read in a Cassiopeia-Tree\n",
    "cm = pd.read_csv(\"test_lg4_character_matrix.txt\", sep='\\t', index_col = 0) # read in the associated character matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post-Process Tree & Add Redundant Leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "removing character strings from sample names: 100%|██████████| 1048/1048 [00:00<00:00, 581509.54it/s]\n"
     ]
    }
   ],
   "source": [
    "g = g.post_process(cm = cm) # Cassiopeia-Tree's have built in functionality to post-process, callable as a method on the object \n",
    "\n",
    "# create a newick string for the given post-processed tree. Note that you need to pass in the \n",
    "# networkx object for this\n",
    "\n",
    "g.newick = utilities.convert_network_to_newick_format(g.network) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now save final tree\n",
    "out_fp = \"test_lg4_tree.processed.pkl\"\n",
    "\n",
    "pic.dump(g, open(out_fp, 'wb'))\n",
    "\n",
    "with open('test_lg4_tree.processed.nwk', 'w') as f:\n",
    "    f.write(out_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final notes\n",
    "\n",
    "Congrats! You've successfully created a character matrix, reconstructed a tree, and post-processed it. You are now at the stage where you can make hypotheses regarding how cells are related to one another, and if you have paired phenotypic measurements for each cell (e.g. single-cell RNAseq), you can start integrating these two orthogonal measurements to see how phenotypes are inherited. \n",
    "\n",
    "To get you started, we have some key suggestions - \n",
    "\n",
    "1. We suggest you take a look at the concordance between alleles and trees. This can be done two ways:\n",
    "    - This can be done by plotting an \"indel heatmap\", which we've provided a script for creating in scripts/alleletable_2_heatmap.py. This will take in an allele table and produce a data structure that resembles a character matrix though it retains the indel identities. You can plot this indel heatmap using [ITOL](https://itol.embl.de/), or another package like [phytools](http://blog.phytools.org/). \n",
    "    - You can explore the relationship between \"allele distance\" and \"phylogenetic distance\". We have provided functionality for computing both of these items simultaneously with `utiliites.compute_pairwise_dist_nx`.\n",
    "    \n",
    "2. As noted above, there are several ways to visualize the tree. We've found success, especially with larger trees, with [ITOL](https://itol.embl.de/).\n",
    "\n",
    "3. There are several packages for doing tree-based analysis that you can use to study evolutionary relationships between cells. We've found the following usefule: [ETE3](http://etetoolkit.org/), [Biopython](https://biopython.org/wiki/Phylo), and [scikit-bio](http://scikit-bio.org/). These have nice functionality around traversing a tree, visualizing sub-clades, and more. All of them have functionality for reading in trees from newick format. \n",
    "\n",
    "4. On integrating RNA-seq and tree information, we recommend using [Hotspot](https://yoseflab.github.io/Hotspot/) which has a module specifically for phylogenetic trees. \n",
    "\n",
    "5. We are currently in the process of building ou the cassiopeia.Analysis module, which thus far only has functionality for running *FitchCount* which quantifies how plastic different states are in a tree given the states at the leaves. You can read more about this in our recent [manuscript](https://www.biorxiv.org/content/10.1101/2020.04.16.045245v2). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
